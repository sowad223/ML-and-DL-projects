{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b068c4e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T07:35:18.176825Z",
     "iopub.status.busy": "2025-05-04T07:35:18.176231Z",
     "iopub.status.idle": "2025-05-04T13:13:44.342825Z",
     "shell.execute_reply": "2025-05-04T13:13:44.342058Z"
    },
    "papermill": {
     "duration": 20306.172058,
     "end_time": "2025-05-04T13:13:44.344302",
     "exception": false,
     "start_time": "2025-05-04T07:35:18.172244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU devices: Tesla T4\n",
      "Additional GPUs: ['Tesla T4']\n",
      "Total samples: 57195\n",
      "Training samples: 45756\n",
      "Validation samples: 11439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/696478548.py:272: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_19/696478548.py:287: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 0.0184, Dice: 0.7216, IoU: 0.6082, F1: 0.7124\n",
      "Val Loss: 0.0086, Dice: 0.8119, IoU: 0.7083, F1: 0.8057\n",
      "Saved best model to 'model-unet.best.pth'\n",
      "Epoch 2/10\n",
      "Train Loss: 0.0078, Dice: 0.8321, IoU: 0.7357, F1: 0.8225\n",
      "Val Loss: 0.0068, Dice: 0.8440, IoU: 0.7526, F1: 0.8330\n",
      "Saved best model to 'model-unet.best.pth'\n",
      "Epoch 3/10\n",
      "Train Loss: 0.0063, Dice: 0.8609, IoU: 0.7746, F1: 0.8494\n",
      "Val Loss: 0.0063, Dice: 0.8568, IoU: 0.7716, F1: 0.8454\n",
      "Saved best model to 'model-unet.best.pth'\n",
      "Epoch 4/10\n",
      "Train Loss: 0.0056, Dice: 0.8728, IoU: 0.7920, F1: 0.8626\n",
      "Val Loss: 0.0052, Dice: 0.8796, IoU: 0.8019, F1: 0.8682\n",
      "Saved best model to 'model-unet.best.pth'\n",
      "Epoch 5/10\n",
      "Train Loss: 0.0051, Dice: 0.8853, IoU: 0.8090, F1: 0.8752\n",
      "Val Loss: 0.0048, Dice: 0.8888, IoU: 0.8156, F1: 0.8778\n",
      "Saved best model to 'model-unet.best.pth'\n",
      "Epoch 6/10\n",
      "Train Loss: 0.0047, Dice: 0.8938, IoU: 0.8211, F1: 0.8833\n",
      "Val Loss: 0.0047, Dice: 0.8854, IoU: 0.8108, F1: 0.8748\n",
      "Saved best model to 'model-unet.best.pth'\n",
      "Epoch 7/10\n",
      "Train Loss: 0.0044, Dice: 0.8990, IoU: 0.8291, F1: 0.8867\n",
      "Val Loss: 0.0045, Dice: 0.8918, IoU: 0.8208, F1: 0.8844\n",
      "Saved best model to 'model-unet.best.pth'\n",
      "Epoch 8/10\n",
      "Train Loss: 0.0042, Dice: 0.9054, IoU: 0.8381, F1: 0.8932\n",
      "Val Loss: 0.0041, Dice: 0.9033, IoU: 0.8373, F1: 0.8919\n",
      "Saved best model to 'model-unet.best.pth'\n",
      "Epoch 9/10\n",
      "Train Loss: 0.0039, Dice: 0.9090, IoU: 0.8450, F1: 0.8951\n",
      "Val Loss: 0.0038, Dice: 0.9093, IoU: 0.8463, F1: 0.8976\n",
      "Saved best model to 'model-unet.best.pth'\n",
      "Epoch 10/10\n",
      "Train Loss: 0.0037, Dice: 0.9134, IoU: 0.8509, F1: 0.9008\n",
      "Val Loss: 0.0038, Dice: 0.9071, IoU: 0.8437, F1: 0.8967\n",
      "Model training complete and saved as 'final_model_unet.pth'.\n",
      "Training history saved as 'training_history.json'.\n",
      "Loss plot saved as 'loss_plot.png'.\n",
      "Dice plot saved as 'dice_plot.png'.\n",
      "Iou plot saved as 'iou_plot.png'.\n",
      "F1 plot saved as 'f1_plot.png'.\n",
      "Mask stats for /kaggle/input/brats2020-training-data/BraTS2020_training_data/content/data/volume_100_slice_100.h5: min=0, max=1, mean=0.0064293981481481485\n",
      "Visualization for sample 1 saved as 'visualization_1.png'\n",
      "Files in working directory: ['f1_plot.png', '__notebook__.ipynb', 'final_model_unet.pth', 'loss_plot.png', 'model-unet.best.pth', 'training_history.json', 'iou_plot.png', 'visualization_1.png', 'dice_plot.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import json\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Verify GPU Availability\n",
    "# -------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU devices: {torch.cuda.get_device_name(0)}\")\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Additional GPUs: {[torch.cuda.get_device_name(i) for i in range(1, torch.cuda.device_count())]}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Define Custom Metrics\n",
    "# -------------------------------\n",
    "def dice_coefficient(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Calculates the Dice Coefficient.\n",
    "    \"\"\"\n",
    "    y_true_f = y_true.view(-1)\n",
    "    y_pred_f = (torch.sigmoid(y_pred) > 0.5).float().view(-1)  # Apply sigmoid and threshold at 0.5\n",
    "    intersection = (y_true_f * y_pred_f).sum()\n",
    "    return (2. * intersection + smooth) / (y_true_f.sum() + y_pred_f.sum() + smooth)\n",
    "\n",
    "def iou_metric(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Calculates the Intersection over Union (IoU) metric.\n",
    "    \"\"\"\n",
    "    y_true_f = y_true.view(-1)\n",
    "    y_pred_f = (torch.sigmoid(y_pred) > 0.5).float().view(-1)  # Apply sigmoid and threshold at 0.5\n",
    "    intersection = (y_true_f * y_pred_f).sum()\n",
    "    union = y_true_f.sum() + y_pred_f.sum() - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "def f1_score(y_true, y_pred, threshold=0.5, eps=1e-7):\n",
    "    \"\"\"\n",
    "    Calculates the F1 Score using Precision and Recall.\n",
    "    \"\"\"\n",
    "    y_pred = (torch.sigmoid(y_pred) > threshold).float()  # Apply sigmoid and threshold at 0.5\n",
    "    y_true_f = y_true.view(-1)\n",
    "    y_pred_f = y_pred.view(-1)\n",
    "    true_positives = (y_true_f * y_pred_f).sum()\n",
    "    precision = true_positives / (y_pred_f.sum() + eps)\n",
    "    recall = true_positives / (y_true_f.sum() + eps)\n",
    "    return 2 * (precision * recall) / (precision + recall + eps)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Define the U-Net Model\n",
    "# -------------------------------\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=4, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        def conv_block(in_ch, out_ch):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        \n",
    "        def upconv_block(in_ch, out_ch):\n",
    "            return nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2)\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = conv_block(in_channels, 64)\n",
    "        self.enc2 = conv_block(64, 128)\n",
    "        self.enc3 = conv_block(128, 256)\n",
    "        self.enc4 = conv_block(256, 512)\n",
    "        self.bottleneck = conv_block(512, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up4 = upconv_block(1024, 512)\n",
    "        self.dec4 = conv_block(1024, 512)\n",
    "        self.up3 = upconv_block(512, 256)\n",
    "        self.dec3 = conv_block(512, 256)\n",
    "        self.up2 = upconv_block(256, 128)\n",
    "        self.dec2 = conv_block(256, 128)\n",
    "        self.up1 = upconv_block(128, 64)\n",
    "        self.dec1 = conv_block(128, 64)\n",
    "        \n",
    "        # Output\n",
    "        self.out_conv = nn.Conv2d(64, out_channels, 1)\n",
    "        # No sigmoid here; BCEWithLogitsLoss applies it internally\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(nn.MaxPool2d(2)(e1))\n",
    "        e3 = self.enc3(nn.MaxPool2d(2)(e2))\n",
    "        e4 = self.enc4(nn.MaxPool2d(2)(e3))\n",
    "        b = self.bottleneck(nn.MaxPool2d(2)(e4))\n",
    "        \n",
    "        # Decoder\n",
    "        d4 = self.up4(b)\n",
    "        d4 = torch.cat([d4, e4], dim=1)\n",
    "        d4 = self.dec4(d4)\n",
    "        d3 = self.up3(d4)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "        d2 = self.up2(d3)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "        d1 = self.up1(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "        \n",
    "        out = self.out_conv(d1)\n",
    "        return out\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Grad-CAM Implementation\n",
    "# -------------------------------\n",
    "class GradCAM:\n",
    "    def __init__(self, model, layer_name):\n",
    "        self.model = model\n",
    "        self.layer_name = layer_name\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients = grad\n",
    "        \n",
    "    def forward_hook(self, module, input, output):\n",
    "        self.activations = output\n",
    "        output.register_hook(self.save_gradient)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        self.model.eval()\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        # Register hook\n",
    "        target_layer = dict(self.model.named_modules())[self.layer_name]\n",
    "        hook = target_layer.register_forward_hook(self.forward_hook)\n",
    "        \n",
    "        # Forward pass\n",
    "        x = x.to(device)\n",
    "        output = self.model(x)\n",
    "        \n",
    "        # Backward pass\n",
    "        self.model.zero_grad()\n",
    "        loss = output.mean()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Compute Grad-CAM\n",
    "        pooled_grads = torch.mean(self.gradients, dim=[0, 2, 3])\n",
    "        heatmap = torch.mean(self.activations * pooled_grads[None, :, None, None], dim=1)\n",
    "        heatmap = nn.functional.relu(heatmap)\n",
    "        heatmap /= torch.max(heatmap) + 1e-8\n",
    "        \n",
    "        hook.remove()\n",
    "        return heatmap.cpu().detach().numpy()\n",
    "\n",
    "def overlay_gradcam(img, heatmap, alpha=0.4):\n",
    "    \"\"\"\n",
    "    Overlays the Grad-CAM heatmap on the input image.\n",
    "    \"\"\"\n",
    "    heatmap = resize(heatmap[0], img.shape[:2], preserve_range=True)\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    jet = plt.get_cmap('jet')\n",
    "    heatmap = jet(heatmap)\n",
    "    heatmap = heatmap[..., :3]  # Remove alpha channel\n",
    "    superimposed_img = heatmap * alpha + img[..., :3]\n",
    "    superimposed_img = np.clip(superimposed_img, 0, 1)\n",
    "    return superimposed_img\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Define the Dataset\n",
    "# -------------------------------\n",
    "class BraTSDataset(Dataset):\n",
    "    def __init__(self, h5_files, data_dir, dim=(128, 128)):\n",
    "        self.h5_files = h5_files\n",
    "        self.data_dir = data_dir\n",
    "        self.dim = dim\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.h5_files)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.data_dir, self.h5_files[idx])\n",
    "        try:\n",
    "            with h5py.File(file_path, 'r') as hf:\n",
    "                if 'image' in hf.keys() and 'mask' in hf.keys():\n",
    "                    image = hf['image'][:]\n",
    "                    mask = hf['mask'][:]\n",
    "                else:\n",
    "                    raise KeyError(f\"Unexpected keys in {file_path}: {list(hf.keys())}\")\n",
    "\n",
    "            if mask.ndim > 2:\n",
    "                mask = np.mean(mask, axis=-1)\n",
    "\n",
    "            if image.shape[:2] != self.dim:\n",
    "                image = resize(\n",
    "                    image, \n",
    "                    (*self.dim, image.shape[2]), \n",
    "                    preserve_range=True, \n",
    "                    anti_aliasing=True\n",
    "                )\n",
    "            \n",
    "            if mask.shape != self.dim:\n",
    "                mask = resize(\n",
    "                    mask, \n",
    "                    self.dim, \n",
    "                    preserve_range=True, \n",
    "                    order=0, \n",
    "                    anti_aliasing=False\n",
    "                )\n",
    "\n",
    "            image_max = np.max(image)\n",
    "            if image_max > 0:\n",
    "                image = image.astype(np.float32) / image_max\n",
    "            else:\n",
    "                image = image.astype(np.float32)\n",
    "\n",
    "            mask_max = np.max(mask)\n",
    "            if mask_max > 0:\n",
    "                mask = mask.astype(np.float32) / mask_max\n",
    "            else:\n",
    "                mask = mask.astype(np.float32)\n",
    "\n",
    "            image = torch.from_numpy(image).permute(2, 0, 1).float()\n",
    "            mask = torch.from_numpy(mask).unsqueeze(0).float()\n",
    "            \n",
    "            return image, mask\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "            return torch.zeros((4, *self.dim)), torch.zeros((1, *self.dim))\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Prepare the Data\n",
    "# -------------------------------\n",
    "data_dir = '/kaggle/input/brats2020-training-data/BraTS2020_training_data/content/data'\n",
    "h5_files = [f for f in os.listdir(data_dir) if f.endswith('.h5')]\n",
    "\n",
    "if not h5_files:\n",
    "    raise FileNotFoundError(f\"No .h5 files found in the directory: {data_dir}\")\n",
    "\n",
    "train_files, val_files = train_test_split(h5_files, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Total samples: {len(h5_files)}\")\n",
    "print(f\"Training samples: {len(train_files)}\")\n",
    "print(f\"Validation samples: {len(val_files)}\")\n",
    "\n",
    "batch_size = 8\n",
    "image_dim = (128, 128)\n",
    "\n",
    "train_dataset = BraTSDataset(train_files, data_dir, dim=image_dim)\n",
    "val_dataset = BraTSDataset(val_files, data_dir, dim=image_dim)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Build and Initialize the Model\n",
    "# -------------------------------\n",
    "model = UNet(in_channels=4, out_channels=1).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Define Training and Validation Loops\n",
    "# -------------------------------\n",
    "def train_epoch(model, loader, optimizer, criterion, scaler):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    metrics = {'dice': 0.0, 'iou': 0.0, 'f1': 0.0}\n",
    "    count = 0\n",
    "    \n",
    "    for images, masks in loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        with torch.no_grad():\n",
    "            metrics['dice'] += dice_coefficient(masks, outputs).item() * images.size(0)\n",
    "            metrics['iou'] += iou_metric(masks, outputs).item() * images.size(0)\n",
    "            metrics['f1'] += f1_score(masks, outputs).item() * images.size(0)\n",
    "        count += images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / count\n",
    "    metrics = {k: v / count for k, v in metrics.items()}\n",
    "    return epoch_loss, metrics\n",
    "\n",
    "def validate_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    metrics = {'dice': 0.0, 'iou': 0.0, 'f1': 0.0}\n",
    "    count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            metrics['dice'] += dice_coefficient(masks, outputs).item() * images.size(0)\n",
    "            metrics['iou'] += iou_metric(masks, outputs).item() * images.size(0)\n",
    "            metrics['f1'] += f1_score(masks, outputs).item() * images.size(0)\n",
    "            count += images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / count\n",
    "    metrics = {k: v / count for k, v in metrics.items()}\n",
    "    return epoch_loss, metrics\n",
    "\n",
    "# -------------------------------\n",
    "# 9. Training Loop\n",
    "# -------------------------------\n",
    "epochs = 10\n",
    "best_val_loss = float('inf')\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_dice': [], 'val_dice': [], \n",
    "           'train_iou': [], 'val_iou': [], 'train_f1': [], 'val_f1': []}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    try:\n",
    "        train_loss, train_metrics = train_epoch(model, train_loader, optimizer, criterion, scaler)\n",
    "        val_loss, val_metrics = validate_epoch(model, val_loader, criterion)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Dice: {train_metrics['dice']:.4f}, IoU: {train_metrics['iou']:.4f}, F1: {train_metrics['f1']:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Dice: {val_metrics['dice']:.4f}, IoU: {val_metrics['iou']:.4f}, F1: {val_metrics['f1']:.4f}\")\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_dice'].append(train_metrics['dice'])\n",
    "        history['val_dice'].append(val_metrics['dice'])\n",
    "        history['train_iou'].append(train_metrics['iou'])\n",
    "        history['val_iou'].append(val_metrics['iou'])\n",
    "        history['train_f1'].append(train_metrics['f1'])\n",
    "        history['val_f1'].append(val_metrics['f1'])\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'model-unet.best.pth')\n",
    "            print(\"Saved best model to 'model-unet.best.pth'\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during epoch {epoch+1}: {e}\")\n",
    "        break\n",
    "\n",
    "# -------------------------------\n",
    "# 10. Save the Final Model\n",
    "# -------------------------------\n",
    "try:\n",
    "    torch.save(model.state_dict(), 'final_model_unet.pth')\n",
    "    print(\"Model training complete and saved as 'final_model_unet.pth'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving final model: {e}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 11. Save Training History\n",
    "# -------------------------------\n",
    "try:\n",
    "    with open('training_history.json', 'w') as f:\n",
    "        json.dump(history, f)\n",
    "    print(\"Training history saved as 'training_history.json'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving training history: {e}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 12. Plot Training History\n",
    "# -------------------------------\n",
    "def plot_training_history(history, metrics=['loss', 'dice', 'iou', 'f1']):\n",
    "    \"\"\"\n",
    "    Plots training and validation metrics over epochs.\n",
    "    \"\"\"\n",
    "    for metric in metrics:\n",
    "        try:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(history[f'train_{metric}'], label=f'Training {metric}')\n",
    "            plt.plot(history[f'val_{metric}'], label=f'Validation {metric}')\n",
    "            plt.title(f'Training and Validation {metric.capitalize()}')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel(metric.capitalize())\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(f'{metric}_plot.png')\n",
    "            plt.close()\n",
    "            print(f\"{metric.capitalize()} plot saved as '{metric}_plot.png'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting {metric}: {e}\")\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# -------------------------------\n",
    "# 13. Preprocess Image for Prediction\n",
    "# -------------------------------\n",
    "def preprocess_image(file_path, image_dim=(128, 128)):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses an image and its corresponding mask from an h5 file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as hf:\n",
    "            if 'image' in hf.keys() and 'mask' in hf.keys():\n",
    "                image = hf['image'][:]\n",
    "                mask = hf['mask'][:]\n",
    "            else:\n",
    "                raise KeyError(f\"Unexpected keys in {file_path}: {list(hf.keys())}\")\n",
    "\n",
    "        print(f\"Mask stats for {file_path}: min={mask.min()}, max={mask.max()}, mean={mask.mean()}\")\n",
    "\n",
    "        if mask.ndim > 2:\n",
    "            mask = np.mean(mask, axis=-1)\n",
    "\n",
    "        if image.shape[:2] != image_dim:\n",
    "            image = resize(image, (*image_dim, image.shape[2]), preserve_range=True, anti_aliasing=True)\n",
    "        if mask.shape != image_dim:\n",
    "            mask = resize(mask, image_dim, preserve_range=True, order=0, anti_aliasing=False)\n",
    "\n",
    "        image_max = np.max(image)\n",
    "        if image_max > 0:\n",
    "            image = image.astype(np.float32) / image_max\n",
    "\n",
    "        mask = (mask - mask.min()) / (mask.max() - mask.min() + 1e-8)\n",
    "\n",
    "        return image, mask\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing {file_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# -------------------------------\n",
    "# 14. Predict and Visualize with Grad-CAM\n",
    "# -------------------------------\n",
    "def predict_and_visualize(file_paths, model, image_dim=(128, 128)):\n",
    "    \"\"\"\n",
    "    Loads, preprocesses, predicts, and visualizes results with Grad-CAM.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    grad_cam = GradCAM(model, 'dec1')\n",
    "    \n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        try:\n",
    "            image, true_mask = preprocess_image(file_path, image_dim)\n",
    "            if image is None or true_mask is None:\n",
    "                continue\n",
    "\n",
    "            img_tensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float().to(device)\n",
    "            with torch.no_grad():\n",
    "                pred_mask = torch.sigmoid(model(img_tensor)).cpu().numpy()[0]  # Apply sigmoid to logits\n",
    "                pred_mask_binary = (pred_mask > 0.5).astype(np.float32)  # Threshold to get binary mask\n",
    "\n",
    "            # Generate Grad-CAM heatmap\n",
    "            heatmap = grad_cam(img_tensor)\n",
    "            superimposed_img = overlay_gradcam(image, heatmap)\n",
    "\n",
    "            # Visualize\n",
    "            plt.figure(figsize=(16, 6))\n",
    "\n",
    "            plt.subplot(1, 4, 1)\n",
    "            plt.imshow(image[..., 0], cmap='gray')\n",
    "            plt.title('Input Image (Channel 0)')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 4, 2)\n",
    "            plt.imshow(true_mask, cmap='gray')\n",
    "            plt.title('True Mask')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 4, 3)\n",
    "            plt.imshow(pred_mask_binary.squeeze(), cmap='gray')\n",
    "            plt.title('Predicted Mask')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 4, 4)\n",
    "            plt.imshow(superimposed_img)\n",
    "            plt.title('Grad-CAM Overlay')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.savefig(f'visualization_{i+1}.png')\n",
    "            plt.close()\n",
    "            print(f\"Visualization for sample {i+1} saved as 'visualization_{i+1}.png'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error visualizing {file_path}: {e}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 15. Specify File Paths and Execute\n",
    "# -------------------------------\n",
    "files_to_predict = [\n",
    "    \"/kaggle/input/brats2020-training-data/BraTS2020_training_data/content/data/volume_100_slice_100.h5\"\n",
    "]\n",
    "try:\n",
    "    predict_and_visualize(files_to_predict, model)\n",
    "except Exception as e:\n",
    "    print(f\"Error during prediction and visualization: {e}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 16. List Output Files\n",
    "# -------------------------------\n",
    "print(\"Files in working directory:\", os.listdir('/kaggle/working'))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 723383,
     "sourceId": 1267593,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20313.346725,
   "end_time": "2025-05-04T13:13:47.266752",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-04T07:35:13.920027",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
